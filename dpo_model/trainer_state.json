{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.4437541601952518,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 5e-05,
      "logits/chosen": -0.45342499017715454,
      "logits/rejected": -0.517052173614502,
      "logps/chosen": -191.5753631591797,
      "logps/rejected": -173.2134246826172,
      "loss": 0.6934,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -0.0007236528908833861,
      "rewards/margins": -0.0004282152804080397,
      "rewards/rejected": -0.000295437581371516,
      "step": 10
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.0001,
      "logits/chosen": -0.4584049582481384,
      "logits/rejected": -0.5235904455184937,
      "logps/chosen": -189.4234161376953,
      "logps/rejected": -178.92593383789062,
      "loss": 0.6919,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 0.005342020653188229,
      "rewards/margins": 0.0024537290446460247,
      "rewards/rejected": 0.002888292074203491,
      "step": 20
    },
    {
      "epoch": 0.01,
      "learning_rate": 0.000145,
      "logits/chosen": -0.4322141706943512,
      "logits/rejected": -0.45009344816207886,
      "logps/chosen": -200.9022674560547,
      "logps/rejected": -181.3295135498047,
      "loss": 0.6879,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": 0.021023573353886604,
      "rewards/margins": 0.01099441759288311,
      "rewards/rejected": 0.010029155761003494,
      "step": 30
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00019500000000000002,
      "logits/chosen": -0.4572924077510834,
      "logits/rejected": -0.5342038869857788,
      "logps/chosen": -197.84471130371094,
      "logps/rejected": -178.21774291992188,
      "loss": 0.6797,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": 0.01892009750008583,
      "rewards/margins": 0.029791096225380898,
      "rewards/rejected": -0.010871000587940216,
      "step": 40
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.000245,
      "logits/chosen": -0.4509410858154297,
      "logits/rejected": -0.5131181478500366,
      "logps/chosen": -191.5374755859375,
      "logps/rejected": -175.35488891601562,
      "loss": 0.6698,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.0061335437931120396,
      "rewards/margins": 0.059258900582790375,
      "rewards/rejected": -0.05312536284327507,
      "step": 50
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.000295,
      "logits/chosen": -0.3692155182361603,
      "logits/rejected": -0.47467923164367676,
      "logps/chosen": -196.581298828125,
      "logps/rejected": -186.78675842285156,
      "loss": 0.652,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.21424894034862518,
      "rewards/margins": 0.14801129698753357,
      "rewards/rejected": -0.36226025223731995,
      "step": 60
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.000345,
      "logits/chosen": -0.1969042867422104,
      "logits/rejected": -0.28334343433380127,
      "logps/chosen": -203.05653381347656,
      "logps/rejected": -180.6920623779297,
      "loss": 0.6587,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.22895601391792297,
      "rewards/margins": 0.16935424506664276,
      "rewards/rejected": -0.39831024408340454,
      "step": 70
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.000395,
      "logits/chosen": -0.41851821541786194,
      "logits/rejected": -0.4831102788448334,
      "logps/chosen": -184.61505126953125,
      "logps/rejected": -187.2899169921875,
      "loss": 0.6386,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": -0.06148488447070122,
      "rewards/margins": 0.24295103549957275,
      "rewards/rejected": -0.3044359087944031,
      "step": 80
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00044500000000000003,
      "logits/chosen": -0.4771033227443695,
      "logits/rejected": -0.5461279153823853,
      "logps/chosen": -189.37152099609375,
      "logps/rejected": -174.15725708007812,
      "loss": 0.6557,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": -0.02966495230793953,
      "rewards/margins": 0.23978812992572784,
      "rewards/rejected": -0.26945310831069946,
      "step": 90
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.000495,
      "logits/chosen": -0.39070576429367065,
      "logits/rejected": -0.45273810625076294,
      "logps/chosen": -200.4268035888672,
      "logps/rejected": -189.39218139648438,
      "loss": 0.6465,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.11806142330169678,
      "rewards/margins": 0.1726325899362564,
      "rewards/rejected": -0.2906940281391144,
      "step": 100
    },
    {
      "epoch": 0.04,
      "eval_logits/chosen": -0.3393443524837494,
      "eval_logits/rejected": -0.43730300664901733,
      "eval_logps/chosen": -184.4080810546875,
      "eval_logps/rejected": -192.3918914794922,
      "eval_loss": 0.6264010667800903,
      "eval_rewards/accuracies": 0.63670414686203,
      "eval_rewards/chosen": -0.05575474351644516,
      "eval_rewards/margins": 0.231553852558136,
      "eval_rewards/rejected": -0.28730863332748413,
      "eval_runtime": 89.4147,
      "eval_samples_per_second": 2.986,
      "eval_steps_per_second": 2.986,
      "step": 100
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0004998766400914329,
      "logits/chosen": -0.48109227418899536,
      "logits/rejected": -0.5150291323661804,
      "logps/chosen": -201.74267578125,
      "logps/rejected": -185.93899536132812,
      "loss": 0.6755,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": -0.16748106479644775,
      "rewards/margins": 0.15996763110160828,
      "rewards/rejected": -0.32744866609573364,
      "step": 110
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0004994503670730125,
      "logits/chosen": -0.4511550962924957,
      "logits/rejected": -0.4875345230102539,
      "logps/chosen": -191.32965087890625,
      "logps/rejected": -174.00186157226562,
      "loss": 0.6596,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.09977506101131439,
      "rewards/margins": 0.16338233649730682,
      "rewards/rejected": -0.06360727548599243,
      "step": 120
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0004987201772071971,
      "logits/chosen": -0.48313602805137634,
      "logits/rejected": -0.5854392647743225,
      "logps/chosen": -197.89877319335938,
      "logps/rejected": -197.77731323242188,
      "loss": 0.6939,
      "rewards/accuracies": 0.5687500238418579,
      "rewards/chosen": -0.20635536313056946,
      "rewards/margins": 0.18564122915267944,
      "rewards/rejected": -0.3919965624809265,
      "step": 130
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0004976869601178609,
      "logits/chosen": -0.3823365569114685,
      "logits/rejected": -0.48094528913497925,
      "logps/chosen": -204.90548706054688,
      "logps/rejected": -215.0174560546875,
      "loss": 0.6807,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": -0.3015155494213104,
      "rewards/margins": 0.22663478553295135,
      "rewards/rejected": -0.5281503796577454,
      "step": 140
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0004963519746208725,
      "logits/chosen": -0.33862054347991943,
      "logits/rejected": -0.4290298819541931,
      "logps/chosen": -187.50726318359375,
      "logps/rejected": -187.43344116210938,
      "loss": 0.6397,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.3410579562187195,
      "rewards/margins": 0.25577741861343384,
      "rewards/rejected": -0.5968353748321533,
      "step": 150
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0004947168471904213,
      "logits/chosen": -0.13890889286994934,
      "logits/rejected": -0.23200520873069763,
      "logps/chosen": -206.5216522216797,
      "logps/rejected": -202.96788024902344,
      "loss": 0.646,
      "rewards/accuracies": 0.706250011920929,
      "rewards/chosen": -0.33091050386428833,
      "rewards/margins": 0.24850532412528992,
      "rewards/rejected": -0.5794159173965454,
      "step": 160
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.000492783569977409,
      "logits/chosen": -0.31781479716300964,
      "logits/rejected": -0.42319732904434204,
      "logps/chosen": -201.2083740234375,
      "logps/rejected": -183.96847534179688,
      "loss": 0.6577,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": -0.1168936938047409,
      "rewards/margins": 0.29392844438552856,
      "rewards/rejected": -0.41082215309143066,
      "step": 170
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0004905544983823213,
      "logits/chosen": -0.3917745053768158,
      "logits/rejected": -0.45829540491104126,
      "logps/chosen": -199.32655334472656,
      "logps/rejected": -195.40005493164062,
      "loss": 0.6576,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": -0.17169232666492462,
      "rewards/margins": 0.33997979760169983,
      "rewards/rejected": -0.5116721391677856,
      "step": 180
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00048803234818553466,
      "logits/chosen": -0.700568675994873,
      "logits/rejected": -0.7688873410224915,
      "logps/chosen": -189.85787963867188,
      "logps/rejected": -198.49447631835938,
      "loss": 0.6449,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": -0.5408006906509399,
      "rewards/margins": 0.3596179187297821,
      "rewards/rejected": -0.9004186391830444,
      "step": 190
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0004852201922385564,
      "logits/chosen": -0.33122819662094116,
      "logits/rejected": -0.4049534201622009,
      "logps/chosen": -207.1273956298828,
      "logps/rejected": -204.17172241210938,
      "loss": 0.6082,
      "rewards/accuracies": 0.668749988079071,
      "rewards/chosen": -0.4911384582519531,
      "rewards/margins": 0.4561786651611328,
      "rewards/rejected": -0.9473171234130859,
      "step": 200
    },
    {
      "epoch": 0.09,
      "eval_logits/chosen": 0.09544627368450165,
      "eval_logits/rejected": -0.007450076285749674,
      "eval_logps/chosen": -191.67906188964844,
      "eval_logps/rejected": -203.23348999023438,
      "eval_loss": 0.6774744987487793,
      "eval_rewards/accuracies": 0.6142321825027466,
      "eval_rewards/chosen": -0.7828542590141296,
      "eval_rewards/margins": 0.5886141657829285,
      "eval_rewards/rejected": -1.371468424797058,
      "eval_runtime": 89.4651,
      "eval_samples_per_second": 2.984,
      "eval_steps_per_second": 2.984,
      "step": 200
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0004821214567202284,
      "logits/chosen": 0.00838010199368,
      "logits/rejected": 0.02958456054329872,
      "logps/chosen": -193.05178833007812,
      "logps/rejected": -185.6856231689453,
      "loss": 0.6969,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.7372509241104126,
      "rewards/margins": 0.3699313998222351,
      "rewards/rejected": -1.107182264328003,
      "step": 210
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0004787399169624562,
      "logits/chosen": -0.10990108549594879,
      "logits/rejected": -0.1618008315563202,
      "logps/chosen": -185.85153198242188,
      "logps/rejected": -175.82374572753906,
      "loss": 0.7305,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.09266118705272675,
      "rewards/margins": 0.10963799059391022,
      "rewards/rejected": -0.20229916274547577,
      "step": 220
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0004750796928505484,
      "logits/chosen": -0.011633934453129768,
      "logits/rejected": -0.14027786254882812,
      "logps/chosen": -190.3789520263672,
      "logps/rejected": -190.18470764160156,
      "loss": 0.6654,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.027495289221405983,
      "rewards/margins": 0.25976863503456116,
      "rewards/rejected": -0.2872639298439026,
      "step": 230
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00047114524380377097,
      "logits/chosen": -0.03011232055723667,
      "logits/rejected": -0.14304369688034058,
      "logps/chosen": -202.06411743164062,
      "logps/rejected": -187.2412872314453,
      "loss": 0.6927,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": -0.613567054271698,
      "rewards/margins": 0.2476947009563446,
      "rewards/rejected": -0.8612618446350098,
      "step": 240
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00046694136334223213,
      "logits/chosen": -0.18557870388031006,
      "logits/rejected": -0.254141628742218,
      "logps/chosen": -199.8090362548828,
      "logps/rejected": -183.81118774414062,
      "loss": 0.6035,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.20200929045677185,
      "rewards/margins": 0.41200438141822815,
      "rewards/rejected": -0.614013671875,
      "step": 250
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.000462473173246716,
      "logits/chosen": -0.158242866396904,
      "logits/rejected": -0.2304009646177292,
      "logps/chosen": -191.0575714111328,
      "logps/rejected": -187.07675170898438,
      "loss": 0.7346,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.004771453328430653,
      "rewards/margins": 0.2194472849369049,
      "rewards/rejected": -0.22421875596046448,
      "step": 260
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00045774611731858207,
      "logits/chosen": -0.17843930423259735,
      "logits/rejected": -0.21074669063091278,
      "logps/chosen": -183.6065673828125,
      "logps/rejected": -179.2596893310547,
      "loss": 0.7093,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.0526541993021965,
      "rewards/margins": 0.20425276458263397,
      "rewards/rejected": -0.15159858763217926,
      "step": 270
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0004527659547473317,
      "logits/chosen": -0.20431891083717346,
      "logits/rejected": -0.26191985607147217,
      "logps/chosen": -189.5477294921875,
      "logps/rejected": -187.91957092285156,
      "loss": 0.6721,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": -0.1828632354736328,
      "rewards/margins": 0.2963308095932007,
      "rewards/rejected": -0.4791940152645111,
      "step": 280
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0004475387530939226,
      "logits/chosen": -0.27255821228027344,
      "logits/rejected": -0.34975674748420715,
      "logps/chosen": -195.4250030517578,
      "logps/rejected": -191.8223876953125,
      "loss": 0.6225,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.13620680570602417,
      "rewards/margins": 0.4464084506034851,
      "rewards/rejected": -0.582615315914154,
      "step": 290
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00044207088089838085,
      "logits/chosen": -0.26971596479415894,
      "logits/rejected": -0.3681274652481079,
      "logps/chosen": -188.78057861328125,
      "logps/rejected": -184.4641571044922,
      "loss": 0.636,
      "rewards/accuracies": 0.643750011920929,
      "rewards/chosen": -0.641865611076355,
      "rewards/margins": 0.4092341959476471,
      "rewards/rejected": -1.0510997772216797,
      "step": 300
    },
    {
      "epoch": 0.13,
      "eval_logits/chosen": -0.26171237230300903,
      "eval_logits/rejected": -0.3482499122619629,
      "eval_logps/chosen": -190.18692016601562,
      "eval_logps/rejected": -202.80047607421875,
      "eval_loss": 0.5890310406684875,
      "eval_rewards/accuracies": 0.6779026389122009,
      "eval_rewards/chosen": -0.6336387991905212,
      "eval_rewards/margins": 0.6945266127586365,
      "eval_rewards/rejected": -1.3281654119491577,
      "eval_runtime": 89.4761,
      "eval_samples_per_second": 2.984,
      "eval_steps_per_second": 2.984,
      "step": 300
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00043636899992071553,
      "logits/chosen": -0.4404048025608063,
      "logits/rejected": -0.4426307678222656,
      "logps/chosen": -204.23397827148438,
      "logps/rejected": -200.93344116210938,
      "loss": 0.666,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": -0.7253533601760864,
      "rewards/margins": 0.4038504660129547,
      "rewards/rejected": -1.1292036771774292,
      "step": 310
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00043044005702459054,
      "logits/chosen": -0.5568861365318298,
      "logits/rejected": -0.6058424711227417,
      "logps/chosen": -211.996337890625,
      "logps/rejected": -203.05801391601562,
      "loss": 0.6665,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": -0.5496628880500793,
      "rewards/margins": 0.37571707367897034,
      "rewards/rejected": -0.9253799319267273,
      "step": 320
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0004242912757136412,
      "logits/chosen": -0.8043859601020813,
      "logits/rejected": -0.8837782144546509,
      "logps/chosen": -182.0735321044922,
      "logps/rejected": -176.51168823242188,
      "loss": 0.6801,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.061840713024139404,
      "rewards/margins": 0.346549391746521,
      "rewards/rejected": -0.4083901047706604,
      "step": 330
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0004179301473307476,
      "logits/chosen": -0.8511207699775696,
      "logits/rejected": -0.8864448666572571,
      "logps/chosen": -197.67918395996094,
      "logps/rejected": -200.24790954589844,
      "loss": 0.6417,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.7549942135810852,
      "rewards/margins": 0.39922478795051575,
      "rewards/rejected": -1.1542189121246338,
      "step": 340
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00041136442193098765,
      "logits/chosen": -0.4981415867805481,
      "logits/rejected": -0.5537856221199036,
      "logps/chosen": -204.8807830810547,
      "logps/rejected": -218.15444946289062,
      "loss": 0.6467,
      "rewards/accuracies": 0.643750011920929,
      "rewards/chosen": -1.058118462562561,
      "rewards/margins": 0.4872983992099762,
      "rewards/rejected": -1.5454169511795044,
      "step": 350
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00040460209883938855,
      "logits/chosen": -0.2731361389160156,
      "logits/rejected": -0.3310987949371338,
      "logps/chosen": -193.4983367919922,
      "logps/rejected": -191.22006225585938,
      "loss": 0.7414,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.886330783367157,
      "rewards/margins": 0.43970125913619995,
      "rewards/rejected": -1.326032280921936,
      "step": 360
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00039765141690498135,
      "logits/chosen": -0.20755355060100555,
      "logits/rejected": -0.26792678236961365,
      "logps/chosen": -202.2141571044922,
      "logps/rejected": -204.55738830566406,
      "loss": 0.7188,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.4008792042732239,
      "rewards/margins": 0.27219507098197937,
      "rewards/rejected": -0.6730743050575256,
      "step": 370
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00039052084446303264,
      "logits/chosen": -0.3804037868976593,
      "logits/rejected": -0.49018383026123047,
      "logps/chosen": -202.04360961914062,
      "logps/rejected": -189.54409790039062,
      "loss": 0.7066,
      "rewards/accuracies": 0.59375,
      "rewards/chosen": -0.07661817967891693,
      "rewards/margins": 0.25306206941604614,
      "rewards/rejected": -0.32968029379844666,
      "step": 380
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00038395669874474915,
      "logits/chosen": -0.2596464455127716,
      "logits/rejected": -0.3771413266658783,
      "logps/chosen": -196.5479736328125,
      "logps/rejected": -190.02696228027344,
      "loss": 0.7254,
      "rewards/accuracies": 0.6312500238418579,
      "rewards/chosen": -0.21401989459991455,
      "rewards/margins": NaN,
      "rewards/rejected": NaN,
      "step": 390
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0003765084410302909,
      "logits/chosen": -0.33287736773490906,
      "logits/rejected": -0.47501811385154724,
      "logps/chosen": -190.00796508789062,
      "logps/rejected": -176.31509399414062,
      "loss": 0.6621,
      "rewards/accuracies": 0.668749988079071,
      "rewards/chosen": -0.29800641536712646,
      "rewards/margins": 0.37215036153793335,
      "rewards/rejected": -0.6701568365097046,
      "step": 400
    },
    {
      "epoch": 0.18,
      "eval_logits/chosen": -0.2423500269651413,
      "eval_logits/rejected": -0.35890546441078186,
      "eval_logps/chosen": -184.3833465576172,
      "eval_logps/rejected": -196.96705627441406,
      "eval_loss": 0.5682221055030823,
      "eval_rewards/accuracies": 0.6853932738304138,
      "eval_rewards/chosen": -0.05328456312417984,
      "eval_rewards/margins": 0.6915388107299805,
      "eval_rewards/rejected": -0.7448234558105469,
      "eval_runtime": 89.4577,
      "eval_samples_per_second": 2.985,
      "eval_steps_per_second": 2.985,
      "step": 400
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00036890605226756886,
      "logits/chosen": -0.33247604966163635,
      "logits/rejected": -0.4079569876194,
      "logps/chosen": -192.8221893310547,
      "logps/rejected": -187.65977478027344,
      "loss": 0.5966,
      "rewards/accuracies": 0.668749988079071,
      "rewards/chosen": -0.06420950591564178,
      "rewards/margins": 0.500837504863739,
      "rewards/rejected": -0.565047025680542,
      "step": 410
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00036115879479623185,
      "logits/chosen": -0.22108490765094757,
      "logits/rejected": -0.2428397238254547,
      "logps/chosen": -183.7821044921875,
      "logps/rejected": -209.1639862060547,
      "loss": 0.6682,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": -0.48159581422805786,
      "rewards/margins": 0.4806106686592102,
      "rewards/rejected": -0.9622064828872681,
      "step": 420
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00035407019806510035,
      "logits/chosen": NaN,
      "logits/rejected": -0.24520520865917206,
      "logps/chosen": NaN,
      "logps/rejected": -195.57388305664062,
      "loss": 0.7232,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": -1.3374128341674805,
      "step": 430
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0003460738306649509,
      "logits/chosen": -0.37720197439193726,
      "logits/rejected": -0.47776541113853455,
      "logps/chosen": -196.36985778808594,
      "logps/rejected": -178.85525512695312,
      "loss": 0.6608,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": -0.40994709730148315,
      "rewards/margins": 0.3967044949531555,
      "rewards/rejected": -0.8066515922546387,
      "step": 440
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00033796041210117545,
      "logits/chosen": -0.538103461265564,
      "logits/rejected": -0.5473518371582031,
      "logps/chosen": -205.6846160888672,
      "logps/rejected": -197.90281677246094,
      "loss": 0.6248,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.29398488998413086,
      "rewards/margins": 0.4159626066684723,
      "rewards/rejected": -0.709947407245636,
      "step": 450
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0003297398273245175,
      "logits/chosen": -0.3733568787574768,
      "logits/rejected": -0.43589964509010315,
      "logps/chosen": -197.49191284179688,
      "logps/rejected": -199.4665069580078,
      "loss": 0.6353,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.4548988938331604,
      "rewards/margins": 0.39296653866767883,
      "rewards/rejected": -0.8478654026985168,
      "step": 460
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0003214220918512434,
      "logits/chosen": -0.2674393057823181,
      "logits/rejected": -0.3983444273471832,
      "logps/chosen": -194.13168334960938,
      "logps/rejected": -182.4646759033203,
      "loss": 0.6822,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": -0.37355154752731323,
      "rewards/margins": 0.3606933057308197,
      "rewards/rejected": -0.7342448234558105,
      "step": 470
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0003130173395607785,
      "logits/chosen": -0.30522850155830383,
      "logits/rejected": -0.3672177195549011,
      "logps/chosen": -195.6197509765625,
      "logps/rejected": -191.63148498535156,
      "loss": 0.6952,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": -0.3236689269542694,
      "rewards/margins": 0.3224283754825592,
      "rewards/rejected": -0.6460973024368286,
      "step": 480
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0003045358103491357,
      "logits/chosen": -0.32792776823043823,
      "logits/rejected": -0.42640408873558044,
      "logps/chosen": -210.19039916992188,
      "logps/rejected": -194.3829803466797,
      "loss": 0.628,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": -0.08077526092529297,
      "rewards/margins": 0.4310273230075836,
      "rewards/rejected": -0.511802613735199,
      "step": 490
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00029598783765318005,
      "logits/chosen": -0.29543596506118774,
      "logits/rejected": -0.3895857036113739,
      "logps/chosen": -192.24661254882812,
      "logps/rejected": -192.8240966796875,
      "loss": 0.627,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.03066401556134224,
      "rewards/margins": 0.48883119225502014,
      "rewards/rejected": -0.5194951891899109,
      "step": 500
    },
    {
      "epoch": 0.22,
      "eval_logits/chosen": -0.17576393485069275,
      "eval_logits/rejected": -0.2671757638454437,
      "eval_logps/chosen": -183.17543029785156,
      "eval_logps/rejected": -196.17774963378906,
      "eval_loss": 0.5647120475769043,
      "eval_rewards/accuracies": 0.704119861125946,
      "eval_rewards/chosen": 0.06751086562871933,
      "eval_rewards/margins": 0.7334052920341492,
      "eval_rewards/rejected": -0.6658943295478821,
      "eval_runtime": 89.4396,
      "eval_samples_per_second": 2.985,
      "eval_steps_per_second": 2.985,
      "step": 500
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0002873838358609274,
      "logits/chosen": -0.35243749618530273,
      "logits/rejected": -0.4266510605812073,
      "logps/chosen": -190.89739990234375,
      "logps/rejected": -188.93283081054688,
      "loss": 0.6743,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.11843930184841156,
      "rewards/margins": 0.3560686409473419,
      "rewards/rejected": -0.4745078980922699,
      "step": 510
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0002787342876232167,
      "logits/chosen": -0.44419288635253906,
      "logits/rejected": -0.5017122030258179,
      "logps/chosen": -184.77767944335938,
      "logps/rejected": -189.05606079101562,
      "loss": 0.7316,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.27557191252708435,
      "rewards/margins": 0.2248462736606598,
      "rewards/rejected": -0.5004181861877441,
      "step": 520
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0002700497310822147,
      "logits/chosen": -0.3465993404388428,
      "logits/rejected": -0.34490957856178284,
      "logps/chosen": -200.07943725585938,
      "logps/rejected": -204.35389709472656,
      "loss": 0.6904,
      "rewards/accuracies": 0.581250011920929,
      "rewards/chosen": -0.2983885407447815,
      "rewards/margins": 0.36207202076911926,
      "rewards/rejected": -0.6604605913162231,
      "step": 530
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00026134074703231344,
      "logits/chosen": -0.20911958813667297,
      "logits/rejected": -0.20905724167823792,
      "logps/chosen": -195.11251831054688,
      "logps/rejected": -188.3310089111328,
      "loss": 0.6749,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.3694916367530823,
      "rewards/margins": 0.35324567556381226,
      "rewards/rejected": -0.7227372527122498,
      "step": 540
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00025261794602906147,
      "logits/chosen": -0.1211995854973793,
      "logits/rejected": -0.2046348601579666,
      "logps/chosen": -199.16094970703125,
      "logps/rejected": -185.33737182617188,
      "loss": 0.6418,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.4402194917201996,
      "rewards/margins": 0.41122913360595703,
      "rewards/rejected": -0.851448655128479,
      "step": 550
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00024389195546183672,
      "logits/chosen": -0.15667076408863068,
      "logits/rejected": -0.24964937567710876,
      "logps/chosen": -202.1864013671875,
      "logps/rejected": -196.75048828125,
      "loss": 0.627,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.1296071708202362,
      "rewards/margins": 0.48790597915649414,
      "rewards/rejected": -0.617513120174408,
      "step": 560
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.00023517340660600964,
      "logits/chosen": -0.16127341985702515,
      "logits/rejected": -0.1585789918899536,
      "logps/chosen": -186.47470092773438,
      "logps/rejected": -177.87306213378906,
      "loss": 0.6702,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.29518792033195496,
      "rewards/margins": 0.33052003383636475,
      "rewards/rejected": -0.6257079839706421,
      "step": 570
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00022647292167037142,
      "logits/chosen": -0.1746787428855896,
      "logits/rejected": -0.23948438465595245,
      "logps/chosen": -193.5236358642578,
      "logps/rejected": -197.8087615966797,
      "loss": 0.587,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -0.13704228401184082,
      "rewards/margins": 0.4703825116157532,
      "rewards/rejected": -0.607424795627594,
      "step": 580
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.00021780110085560934,
      "logits/chosen": -0.15575461089611053,
      "logits/rejected": -0.2257671356201172,
      "logps/chosen": -200.4638214111328,
      "logps/rejected": -197.76419067382812,
      "loss": 0.6239,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.31462734937667847,
      "rewards/margins": 0.45962971448898315,
      "rewards/rejected": -0.7742570638656616,
      "step": 590
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00020916850943959451,
      "logits/chosen": -0.22305604815483093,
      "logits/rejected": -0.27892249822616577,
      "logps/chosen": -200.7952117919922,
      "logps/rejected": -190.30990600585938,
      "loss": 0.6796,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": -0.6852676868438721,
      "rewards/margins": 0.3779904842376709,
      "rewards/rejected": -1.063258171081543,
      "step": 600
    },
    {
      "epoch": 0.27,
      "eval_logits/chosen": NaN,
      "eval_logits/rejected": -0.17416323721408844,
      "eval_logps/chosen": NaN,
      "eval_logps/rejected": -201.04129028320312,
      "eval_loss": NaN,
      "eval_rewards/accuracies": 0.7453183531761169,
      "eval_rewards/chosen": NaN,
      "eval_rewards/margins": NaN,
      "eval_rewards/rejected": -1.1522467136383057,
      "eval_runtime": 89.3865,
      "eval_samples_per_second": 2.987,
      "eval_steps_per_second": 2.987,
      "step": 600
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.00020058566490521845,
      "logits/chosen": -0.20125579833984375,
      "logits/rejected": -0.1924213171005249,
      "logps/chosen": -203.76611328125,
      "logps/rejected": -201.08334350585938,
      "loss": 0.7181,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": -0.5597121119499207,
      "rewards/margins": 0.28746527433395386,
      "rewards/rejected": -0.8471775054931641,
      "step": 610
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001920630241264607,
      "logits/chosen": -0.22756712138652802,
      "logits/rejected": -0.2978711724281311,
      "logps/chosen": -196.51394653320312,
      "logps/rejected": -194.6320037841797,
      "loss": 0.6448,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": -0.2589941620826721,
      "rewards/margins": 0.3888741433620453,
      "rewards/rejected": -0.6478683352470398,
      "step": 620
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0001836109706282978,
      "logits/chosen": -0.24186234176158905,
      "logits/rejected": -0.32926174998283386,
      "logps/chosen": -184.669921875,
      "logps/rejected": -183.69557189941406,
      "loss": 0.6437,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.20827066898345947,
      "rewards/margins": 0.42390233278274536,
      "rewards/rejected": -0.6321730017662048,
      "step": 630
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00017523980193597836,
      "logits/chosen": -0.2905571758747101,
      "logits/rejected": -0.3474876284599304,
      "logps/chosen": -196.31314086914062,
      "logps/rejected": -198.09130859375,
      "loss": 0.6067,
      "rewards/accuracies": 0.668749988079071,
      "rewards/chosen": -0.29306668043136597,
      "rewards/margins": 0.5631123185157776,
      "rewards/rejected": -0.8561789393424988,
      "step": 640
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00016695971702907424,
      "logits/chosen": -0.3451116681098938,
      "logits/rejected": -0.4060901701450348,
      "logps/chosen": -195.0838623046875,
      "logps/rejected": -210.522705078125,
      "loss": 0.6858,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": -0.28453338146209717,
      "rewards/margins": 0.4316927492618561,
      "rewards/rejected": -0.7162261605262756,
      "step": 650
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.00015878080391559508,
      "logits/chosen": -0.29778286814689636,
      "logits/rejected": -0.3974761366844177,
      "logps/chosen": -190.7740478515625,
      "logps/rejected": -189.48858642578125,
      "loss": 0.6614,
      "rewards/accuracies": 0.643750011920929,
      "rewards/chosen": -0.3506911098957062,
      "rewards/margins": 0.42732053995132446,
      "rewards/rejected": -0.778011679649353,
      "step": 660
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00015071302734130488,
      "logits/chosen": -0.3861157298088074,
      "logits/rejected": -0.4376472532749176,
      "logps/chosen": -198.9647979736328,
      "logps/rejected": -207.7519073486328,
      "loss": 0.6022,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.3761836886405945,
      "rewards/margins": 0.5417288541793823,
      "rewards/rejected": -0.917912483215332,
      "step": 670
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00014355517710873183,
      "logits/chosen": NaN,
      "logits/rejected": -0.3391726315021515,
      "logps/chosen": NaN,
      "logps/rejected": -190.10787963867188,
      "loss": 0.6137,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": NaN,
      "rewards/margins": NaN,
      "rewards/rejected": -0.7871343493461609,
      "step": 680
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.00013572551823532654,
      "logits/chosen": -0.26592817902565,
      "logits/rejected": -0.35060805082321167,
      "logps/chosen": -194.94760131835938,
      "logps/rejected": -178.78704833984375,
      "loss": 0.6012,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.2716275453567505,
      "rewards/margins": 0.6055738925933838,
      "rewards/rejected": -0.8772014379501343,
      "step": 690
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0001280350852153168,
      "logits/chosen": -0.26685354113578796,
      "logits/rejected": -0.2607955038547516,
      "logps/chosen": -164.87051391601562,
      "logps/rejected": -186.02342224121094,
      "loss": 0.6054,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": -0.2601297199726105,
      "rewards/margins": 0.49365028738975525,
      "rewards/rejected": -0.753779947757721,
      "step": 700
    },
    {
      "epoch": 0.31,
      "eval_logits/chosen": -0.16331209242343903,
      "eval_logits/rejected": -0.2678872346878052,
      "eval_logps/chosen": -183.82298278808594,
      "eval_logps/rejected": -198.35316467285156,
      "eval_loss": 0.4940270185470581,
      "eval_rewards/accuracies": 0.737827718257904,
      "eval_rewards/chosen": 0.00275385077111423,
      "eval_rewards/margins": 0.8861896395683289,
      "eval_rewards/rejected": -0.8834357261657715,
      "eval_runtime": 89.3927,
      "eval_samples_per_second": 2.987,
      "eval_steps_per_second": 2.987,
      "step": 700
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00012049324765671748,
      "logits/chosen": -0.415174663066864,
      "logits/rejected": -0.4470624029636383,
      "logps/chosen": -199.84121704101562,
      "logps/rejected": -198.40509033203125,
      "loss": 0.5949,
      "rewards/accuracies": 0.6812499761581421,
      "rewards/chosen": -0.14102990925312042,
      "rewards/margins": 0.5453219413757324,
      "rewards/rejected": -0.6863518357276917,
      "step": 710
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00011310919412686246,
      "logits/chosen": -0.3473227620124817,
      "logits/rejected": -0.4240821897983551,
      "logps/chosen": -195.6846923828125,
      "logps/rejected": -188.4892120361328,
      "loss": 0.6092,
      "rewards/accuracies": 0.668749988079071,
      "rewards/chosen": -0.14641615748405457,
      "rewards/margins": 0.500645637512207,
      "rewards/rejected": -0.647061824798584,
      "step": 720
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00010589192095755171,
      "logits/chosen": -0.2339954823255539,
      "logits/rejected": -0.33984532952308655,
      "logps/chosen": -205.94894409179688,
      "logps/rejected": -194.11911010742188,
      "loss": 0.6005,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.030573230236768723,
      "rewards/margins": 0.6091800332069397,
      "rewards/rejected": -0.5786067843437195,
      "step": 730
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.885022128440629e-05,
      "logits/chosen": -0.32854610681533813,
      "logits/rejected": -0.4403499960899353,
      "logps/chosen": -193.14990234375,
      "logps/rejected": -196.09291076660156,
      "loss": 0.6563,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.052464790642261505,
      "rewards/margins": 0.34373655915260315,
      "rewards/rejected": -0.39620137214660645,
      "step": 740
    },
    {
      "epoch": 0.33,
      "learning_rate": 9.199267433378728e-05,
      "logits/chosen": -0.4149828851222992,
      "logits/rejected": -0.4684049189090729,
      "logps/chosen": -206.9005584716797,
      "logps/rejected": -186.0770721435547,
      "loss": 0.6519,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.1817251443862915,
      "rewards/margins": 0.3133360743522644,
      "rewards/rejected": -0.4950612485408783,
      "step": 750
    },
    {
      "epoch": 0.34,
      "learning_rate": 8.532763497032986e-05,
      "logits/chosen": -0.2840351462364197,
      "logits/rejected": -0.39055365324020386,
      "logps/chosen": -182.90089416503906,
      "logps/rejected": -180.0272674560547,
      "loss": 0.5743,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": -0.0350356288254261,
      "rewards/margins": 0.5650798082351685,
      "rewards/rejected": -0.6001153588294983,
      "step": 760
    },
    {
      "epoch": 0.34,
      "learning_rate": 7.886322351782782e-05,
      "logits/chosen": -0.33218318223953247,
      "logits/rejected": -0.3542303442955017,
      "logps/chosen": -201.6597137451172,
      "logps/rejected": -196.63003540039062,
      "loss": 0.6066,
      "rewards/accuracies": 0.6812499761581421,
      "rewards/chosen": -0.149362713098526,
      "rewards/margins": 0.5244249105453491,
      "rewards/rejected": -0.6737874746322632,
      "step": 770
    },
    {
      "epoch": 0.35,
      "learning_rate": 7.260731586586983e-05,
      "logits/chosen": -0.385100781917572,
      "logits/rejected": -0.43927931785583496,
      "logps/chosen": -197.43319702148438,
      "logps/rejected": -193.08827209472656,
      "loss": 0.6007,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": -0.1556464433670044,
      "rewards/margins": 0.5175602436065674,
      "rewards/rejected": -0.6732066869735718,
      "step": 780
    },
    {
      "epoch": 0.35,
      "learning_rate": 6.656753387428089e-05,
      "logits/chosen": -0.3257206976413727,
      "logits/rejected": -0.35123318433761597,
      "logps/chosen": -206.5318145751953,
      "logps/rejected": -198.60992431640625,
      "loss": 0.6455,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.08848540484905243,
      "rewards/margins": 0.43163996934890747,
      "rewards/rejected": -0.5201253890991211,
      "step": 790
    },
    {
      "epoch": 0.36,
      "learning_rate": 6.075123608706093e-05,
      "logits/chosen": -0.21221968531608582,
      "logits/rejected": -0.25612375140190125,
      "logps/chosen": -192.82522583007812,
      "logps/rejected": -189.10769653320312,
      "loss": 0.5571,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.08098990470170975,
      "rewards/margins": 0.6799068450927734,
      "rewards/rejected": -0.7608968019485474,
      "step": 800
    },
    {
      "epoch": 0.36,
      "eval_logits/chosen": -0.13667826354503632,
      "eval_logits/rejected": -0.23909524083137512,
      "eval_logps/chosen": -183.65931701660156,
      "eval_logps/rejected": -199.16171264648438,
      "eval_loss": 0.4755626618862152,
      "eval_rewards/accuracies": 0.779026210308075,
      "eval_rewards/chosen": 0.01912025175988674,
      "eval_rewards/margins": 0.9834077954292297,
      "eval_rewards/rejected": -0.9642875790596008,
      "eval_runtime": 89.417,
      "eval_samples_per_second": 2.986,
      "eval_steps_per_second": 2.986,
      "step": 800
    },
    {
      "epoch": 0.36,
      "learning_rate": 5.5165508767131415e-05,
      "logits/chosen": -0.3655398488044739,
      "logits/rejected": -0.41961902379989624,
      "logps/chosen": -200.13156127929688,
      "logps/rejected": -188.187255859375,
      "loss": 0.5396,
      "rewards/accuracies": 0.71875,
      "rewards/chosen": -0.15268737077713013,
      "rewards/margins": 0.6861211657524109,
      "rewards/rejected": -0.8388086557388306,
      "step": 810
    },
    {
      "epoch": 0.36,
      "learning_rate": 4.981715726281666e-05,
      "logits/chosen": -0.16776908934116364,
      "logits/rejected": -0.2279486209154129,
      "logps/chosen": -189.06072998046875,
      "logps/rejected": -186.55819702148438,
      "loss": 0.6327,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": -0.30231544375419617,
      "rewards/margins": 0.5014320015907288,
      "rewards/rejected": -0.8037475347518921,
      "step": 820
    },
    {
      "epoch": 0.37,
      "learning_rate": 4.471269771657399e-05,
      "logits/chosen": -0.29681116342544556,
      "logits/rejected": -0.3097909688949585,
      "logps/chosen": -210.3720703125,
      "logps/rejected": -196.7303924560547,
      "loss": 0.5839,
      "rewards/accuracies": 0.731249988079071,
      "rewards/chosen": -0.11049548536539078,
      "rewards/margins": 0.59706050157547,
      "rewards/rejected": -0.7075560688972473,
      "step": 830
    },
    {
      "epoch": 0.37,
      "learning_rate": 3.985834912607894e-05,
      "logits/chosen": -0.21795468032360077,
      "logits/rejected": -0.2983171045780182,
      "logps/chosen": -198.17446899414062,
      "logps/rejected": -182.45864868164062,
      "loss": 0.6256,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": -0.16026119887828827,
      "rewards/margins": 0.5116961598396301,
      "rewards/rejected": -0.6719573736190796,
      "step": 840
    },
    {
      "epoch": 0.38,
      "learning_rate": 3.526002576733389e-05,
      "logits/chosen": -0.2649410367012024,
      "logits/rejected": -0.3237905502319336,
      "logps/chosen": -201.85623168945312,
      "logps/rejected": -207.75717163085938,
      "loss": 0.5974,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.10955385863780975,
      "rewards/margins": 0.5741437673568726,
      "rewards/rejected": -0.6836975812911987,
      "step": 850
    },
    {
      "epoch": 0.38,
      "learning_rate": 3.092332998903416e-05,
      "logits/chosen": -0.23912644386291504,
      "logits/rejected": -0.2840454578399658,
      "logps/chosen": -199.71665954589844,
      "logps/rejected": -182.03073120117188,
      "loss": 0.645,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": -0.08771578222513199,
      "rewards/margins": 0.44828885793685913,
      "rewards/rejected": -0.5360046625137329,
      "step": 860
    },
    {
      "epoch": 0.39,
      "learning_rate": 2.6853545386968604e-05,
      "logits/chosen": -0.25139737129211426,
      "logits/rejected": -0.2729872465133667,
      "logps/chosen": -192.55319213867188,
      "logps/rejected": -200.7825164794922,
      "loss": 0.6287,
      "rewards/accuracies": 0.65625,
      "rewards/chosen": -0.04922059178352356,
      "rewards/margins": 0.5539559721946716,
      "rewards/rejected": -0.6031765937805176,
      "step": 870
    },
    {
      "epoch": 0.39,
      "learning_rate": 2.3055630366772858e-05,
      "logits/chosen": -0.22194917500019073,
      "logits/rejected": -0.27712443470954895,
      "logps/chosen": -192.7534637451172,
      "logps/rejected": -180.44021606445312,
      "loss": 0.6276,
      "rewards/accuracies": 0.668749988079071,
      "rewards/chosen": -0.18818175792694092,
      "rewards/margins": 0.46800661087036133,
      "rewards/rejected": -0.6561883687973022,
      "step": 880
    },
    {
      "epoch": 0.39,
      "learning_rate": 1.95342121028749e-05,
      "logits/chosen": -0.29396677017211914,
      "logits/rejected": -0.31828808784484863,
      "logps/chosen": -188.21279907226562,
      "logps/rejected": -198.68603515625,
      "loss": 0.5703,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -0.10425269603729248,
      "rewards/margins": 0.5625085830688477,
      "rewards/rejected": -0.6667612791061401,
      "step": 890
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.629358090099639e-05,
      "logits/chosen": -0.2728632092475891,
      "logits/rejected": -0.31907302141189575,
      "logps/chosen": -209.6174774169922,
      "logps/rejected": -185.76071166992188,
      "loss": 0.6016,
      "rewards/accuracies": 0.6937500238418579,
      "rewards/chosen": -0.045877136290073395,
      "rewards/margins": 0.5597708225250244,
      "rewards/rejected": -0.6056479811668396,
      "step": 900
    },
    {
      "epoch": 0.4,
      "eval_logits/chosen": -0.1165737733244896,
      "eval_logits/rejected": -0.2173750251531601,
      "eval_logps/chosen": -182.5277099609375,
      "eval_logps/rejected": -198.1944122314453,
      "eval_loss": 0.46251875162124634,
      "eval_rewards/accuracies": 0.7752808928489685,
      "eval_rewards/chosen": 0.13228075206279755,
      "eval_rewards/margins": 0.9998404383659363,
      "eval_rewards/rejected": -0.8675596714019775,
      "eval_runtime": 89.3966,
      "eval_samples_per_second": 2.987,
      "eval_steps_per_second": 2.987,
      "step": 900
    },
    {
      "epoch": 0.4,
      "learning_rate": 1.333768497107593e-05,
      "logits/chosen": -0.23176980018615723,
      "logits/rejected": -0.28035008907318115,
      "logps/chosen": -192.8876495361328,
      "logps/rejected": -192.61436462402344,
      "loss": 0.5904,
      "rewards/accuracies": 0.675000011920929,
      "rewards/chosen": 0.00601470610126853,
      "rewards/margins": 0.5415676236152649,
      "rewards/rejected": -0.5355528593063354,
      "step": 910
    },
    {
      "epoch": 0.41,
      "learning_rate": 1.067012561698319e-05,
      "logits/chosen": -0.24649295210838318,
      "logits/rejected": -0.35097962617874146,
      "logps/chosen": -202.29393005371094,
      "logps/rejected": -191.3699493408203,
      "loss": 0.5939,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.07029281556606293,
      "rewards/margins": 0.6148915886878967,
      "rewards/rejected": -0.6851843595504761,
      "step": 920
    },
    {
      "epoch": 0.41,
      "learning_rate": 8.294152848885156e-06,
      "logits/chosen": -0.2138810157775879,
      "logits/rejected": -0.2571801543235779,
      "logps/chosen": -193.88613891601562,
      "logps/rejected": -190.33721923828125,
      "loss": 0.6077,
      "rewards/accuracies": 0.7437499761581421,
      "rewards/chosen": -0.12425492703914642,
      "rewards/margins": 0.527013897895813,
      "rewards/rejected": -0.6512688398361206,
      "step": 930
    },
    {
      "epoch": 0.42,
      "learning_rate": 6.212661423609184e-06,
      "logits/chosen": -0.31905287504196167,
      "logits/rejected": -0.31355005502700806,
      "logps/chosen": -212.9033966064453,
      "logps/rejected": -197.45217895507812,
      "loss": 0.6435,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": -0.06813552230596542,
      "rewards/margins": 0.4575285017490387,
      "rewards/rejected": -0.5256639719009399,
      "step": 940
    },
    {
      "epoch": 0.42,
      "learning_rate": 4.4281873178278475e-06,
      "logits/chosen": -0.20851095020771027,
      "logits/rejected": -0.32312965393066406,
      "logps/chosen": -204.3595428466797,
      "logps/rejected": -198.91122436523438,
      "loss": 0.5046,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": 0.10759065300226212,
      "rewards/margins": 0.7492339611053467,
      "rewards/rejected": -0.6416434049606323,
      "step": 950
    },
    {
      "epoch": 0.43,
      "learning_rate": 2.942904638361804e-06,
      "logits/chosen": -0.21209099888801575,
      "logits/rejected": -0.3362540304660797,
      "logps/chosen": -185.49819946289062,
      "logps/rejected": -179.66107177734375,
      "loss": 0.56,
      "rewards/accuracies": 0.7250000238418579,
      "rewards/chosen": 0.018016841262578964,
      "rewards/margins": 0.5875195264816284,
      "rewards/rejected": -0.5695026516914368,
      "step": 960
    },
    {
      "epoch": 0.43,
      "learning_rate": 1.7586229733657643e-06,
      "logits/chosen": -0.21231059730052948,
      "logits/rejected": -0.254902184009552,
      "logps/chosen": -194.56546020507812,
      "logps/rejected": -202.79237365722656,
      "loss": 0.6175,
      "rewards/accuracies": 0.606249988079071,
      "rewards/chosen": -0.07401187717914581,
      "rewards/margins": 0.45067650079727173,
      "rewards/rejected": -0.5246883630752563,
      "step": 970
    },
    {
      "epoch": 0.43,
      "learning_rate": 8.767851876239075e-07,
      "logits/chosen": -0.24298641085624695,
      "logits/rejected": -0.31803399324417114,
      "logps/chosen": -201.12661743164062,
      "logps/rejected": -187.25924682617188,
      "loss": 0.6199,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": -0.13379442691802979,
      "rewards/margins": 0.5511313080787659,
      "rewards/rejected": -0.6849257349967957,
      "step": 980
    },
    {
      "epoch": 0.44,
      "learning_rate": 2.9846566464150627e-07,
      "logits/chosen": -0.21196453273296356,
      "logits/rejected": -0.2878018915653229,
      "logps/chosen": -196.87367248535156,
      "logps/rejected": -185.54867553710938,
      "loss": 0.6299,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": -0.012259108014404774,
      "rewards/margins": 0.441129207611084,
      "rewards/rejected": -0.4533882737159729,
      "step": 990
    },
    {
      "epoch": 0.44,
      "learning_rate": 2.4368997673940296e-08,
      "logits/chosen": -0.24899165332317352,
      "logits/rejected": -0.2938481271266937,
      "logps/chosen": -179.53005981445312,
      "logps/rejected": -187.016357421875,
      "loss": 0.6448,
      "rewards/accuracies": 0.6187499761581421,
      "rewards/chosen": 0.0126511724665761,
      "rewards/margins": 0.46844252943992615,
      "rewards/rejected": -0.4557913839817047,
      "step": 1000
    },
    {
      "epoch": 0.44,
      "eval_logits/chosen": -0.1266145557165146,
      "eval_logits/rejected": -0.22705206274986267,
      "eval_logps/chosen": -182.44728088378906,
      "eval_logps/rejected": -198.11062622070312,
      "eval_loss": 0.4614259600639343,
      "eval_rewards/accuracies": 0.7752808928489685,
      "eval_rewards/chosen": 0.14032290875911713,
      "eval_rewards/margins": 0.9995037317276001,
      "eval_rewards/rejected": -0.8591806292533875,
      "eval_runtime": 89.3588,
      "eval_samples_per_second": 2.988,
      "eval_steps_per_second": 2.988,
      "step": 1000
    }
  ],
  "max_steps": 1000,
  "num_train_epochs": 1,
  "total_flos": 0.0,
  "trial_name": null,
  "trial_params": null
}
