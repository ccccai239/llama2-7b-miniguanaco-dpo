# llama2-7b-miniguanaco-dpo
Two-stage fine-tuning model (SFT+DPO) based on llama2-7b-chat
